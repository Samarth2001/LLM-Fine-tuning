{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIvd7QI9c50U"
      },
      "source": [
        "# Fine-tuning DeepSeek 6.7B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKXvijiDcwPV"
      },
      "source": [
        "# Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xujX9iaQm0Vg",
        "outputId": "240da17e-2395-40d8-c5fb-3e039bdfd2fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: transformers 4.53.0\n",
            "Uninstalling transformers-4.53.0:\n",
            "  Successfully uninstalled transformers-4.53.0\n",
            "Found existing installation: accelerate 1.8.1\n",
            "Uninstalling accelerate-1.8.1:\n",
            "  Successfully uninstalled accelerate-1.8.1\n",
            "Found existing installation: peft 0.15.2\n",
            "Uninstalling peft-0.15.2:\n",
            "  Successfully uninstalled peft-0.15.2\n",
            "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: datasets 2.14.4\n",
            "Uninstalling datasets-2.14.4:\n",
            "  Successfully uninstalled datasets-2.14.4\n",
            "\u001b[33mWARNING: Skipping trl as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mFound existing installation: scipy 1.15.3\n",
            "Uninstalling scipy-1.15.3:\n",
            "  Successfully uninstalled scipy-1.15.3\n",
            "Found existing installation: triton 3.2.0\n",
            "Uninstalling triton-3.2.0:\n",
            "  Successfully uninstalled triton-3.2.0\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m129.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\n",
            "sentence-transformers 4.1.0 requires scipy, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires scipy, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires scipy, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.2/245.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "plotnine 0.14.6 requires scipy<1.16.0,>=1.8.0, but you have scipy 1.16.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires triton==3.2.0; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have triton 3.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://jllllll.github.io/bitsandbytes-windows-webui\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Collecting triton==3.2.0 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Using cached triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "Installing collected packages: triton\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.3.1\n",
            "    Uninstalling triton-3.3.1:\n",
            "      Successfully uninstalled triton-3.3.1\n",
            "Successfully installed triton-3.2.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "fb2df8f9358e486898a8a6c75ce68e8d",
              "pip_warning": {
                "packages": [
                  "triton"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall -y transformers accelerate peft bitsandbytes datasets trl scipy triton\n",
        "!pip install --upgrade transformers==4.41.2 -q\n",
        "!pip install --upgrade peft==0.11.1 -q\n",
        "!pip install --upgrade accelerate==0.30.1 -q\n",
        "!pip install bitsandbytes -q\n",
        "!pip install --upgrade datasets==2.19.1 -q\n",
        "!pip install --upgrade trl==0.8.6 -q\n",
        "!pip install --upgrade scipy -q\n",
        "!pip install --upgrade triton -q\n",
        "\n",
        "# Attempting to install bitsandbytes from a potentially more compatible source\n",
        "!pip install bitsandbytes --prefer-binary --extra-index-url=https://jllllll.github.io/bitsandbytes-windows-webui"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k2DDFwGR4jL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ojjCvAAuaO-"
      },
      "source": [
        "# Configuration and Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcYcJttOuxWg",
        "outputId": "70b86ad8-d191-4962-fafe-94cbbef970f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodeGen-2B Configuration:\n",
            "  Model: Salesforce/codegen-2B-mono\n",
            "  Dataset: sahil2801/CodeAlpaca-20k\n",
            "  Samples: train[:1500]\n",
            "  LoRA Rank: 16\n",
            "  Sequence Length: 768\n"
          ]
        }
      ],
      "source": [
        "# Model - CodeGen 2B mono \n",
        "MODEL_NAME = \"Salesforce/codegen-2B-mono\"  # Mono = Python-focused\n",
        "\n",
        "# Dataset \n",
        "DATASET_NAME = \"sahil2801/CodeAlpaca-20k\"\n",
        "DATASET_SPLIT = \"train[:1500]\"   \n",
        "\n",
        "# Training parameters optimized for CodeGen\n",
        "LORA_R = 16  # Good for 2B model\n",
        "BATCH_SIZE = 1\n",
        "SEQ_LENGTH = 768  # CodeGen handles up to 2048, but 768 is efficient\n",
        "EPOCHS = 1\n",
        "\n",
        "print(f\"CodeGen-2B Configuration:\")\n",
        "print(f\"  Model: {MODEL_NAME}\")\n",
        "print(f\"  Dataset: {DATASET_NAME}\")\n",
        "print(f\"  Samples: {DATASET_SPLIT}\")\n",
        "print(f\"  LoRA Rank: {LORA_R}\")\n",
        "print(f\"  Sequence Length: {SEQ_LENGTH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGGfUc66dhZA"
      },
      "source": [
        "# Imports and GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGReiBy7R4gB",
        "outputId": "d7efa8cb-dad7-4215-f8e2-8c04626ae74a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- GPU Information ---\n",
            "GPU Detected: Tesla T4\n",
            "Total Memory: 14.74 GB\n",
            "Current Usage: 0.00 GB\n",
            "-----------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import gc\n",
        "import time\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        "    TrainingArguments\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "\n",
        "# Clear Memory & Check GPU\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"--- GPU Information ---\")\n",
        "    print(f\"GPU Detected: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Total Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    print(f\"Current Usage: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
        "    print(f\"-----------------------\")\n",
        "else:\n",
        "    print(\"No GPU detected. This will be very slow.\")\n",
        "    raise RuntimeError(\"GPU required for 7B model fine-tuning\")\n",
        "\n",
        "# Memory tracking function\n",
        "def print_gpu_memory(stage=\"\"):\n",
        "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
        "    reserved = torch.cuda.memory_reserved() / 1024**3\n",
        "    print(f\"\\n--- GPU Memory {stage} ---\")\n",
        "    print(f\"Allocated: {allocated:.2f} GB\")\n",
        "    print(f\"Reserved: {reserved:.2f} GB\")\n",
        "    print(f\"--------------------------\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghnciZK3dkY5"
      },
      "source": [
        "# Configure Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztAhap_SvBkv",
        "outputId": "ad2d5f6d-6e67-44bd-c36d-c7c04ab98fd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Quantization configured for CodeGen-2B\n"
          ]
        }
      ],
      "source": [
        "# QLoRA config optimized for CodeGen-2B\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16  # float16 for CodeGen\n",
        ")\n",
        "\n",
        "print(\"Quantization configured for CodeGen-2B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ArCCZ1Pdncd"
      },
      "source": [
        "# Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw0TccofvFHQ",
        "outputId": "68318ea6-a8ba-4a7f-fd75-015c15ce72bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔄 Loading Salesforce/codegen-2B-mono...\n",
            "✅ CodeGen-2B loaded successfully in 22.9 seconds!\n",
            "\n",
            "--- GPU Memory After Model Loading ---\n",
            "Allocated: 1.84 GB\n",
            "Reserved: 1.85 GB\n",
            "--------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"\\n Loading {MODEL_NAME}...\")\n",
        "start_load_time = time.time()\n",
        "\n",
        "# Load tokenizer - CodeGen uses GPT-2 tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "# CodeGen specific: ensure padding token is set\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"  # CodeGen prefers left padding\n",
        "\n",
        "# Load model with 4-bit quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    use_cache=False,\n",
        "    torch_dtype=torch.float16,  # Specify dtype\n",
        ")\n",
        "\n",
        "print(f\"CodeGen-2B loaded successfully in {time.time() - start_load_time:.1f} seconds!\")\n",
        "print_gpu_memory(\"After Model Loading\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eidzJVG1dqNn"
      },
      "source": [
        "# Prepare Model for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZcd6LVPwfjf",
        "outputId": "f70b130f-b436-4a74-c319-f81d03e85a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model prepared for training.\n"
          ]
        }
      ],
      "source": [
        "# Prepare model for k-bit training\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "# Enable gradient checkpointing for memory efficiency\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "print(\"Model prepared for training.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qsNM3wPduDa"
      },
      "source": [
        "# Configure LoRA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Or3ob7kQwhTT",
        "outputId": "b239d598-1418-4a1e-b165-18c4ce0b51bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target modules for LoRA: all-linear\n"
          ]
        }
      ],
      "source": [
        "if \"codegen\" in MODEL_NAME.lower():\n",
        "    # CodeGen uses these module names\n",
        "    target_modules = [\n",
        "        \"transformer.h.*.attn.q_proj\",\n",
        "        \"transformer.h.*.attn.v_proj\",\n",
        "        # Alternative names that might work:\n",
        "        # \"attn.q_proj\",\n",
        "        # \"attn.v_proj\",\n",
        "        # \"transformer.h.*.attn.c_attn\",  # Combined attention\n",
        "    ]\n",
        "\n",
        "    # Simpler approach - just use the attention projection\n",
        "    target_modules = [\"attn.c_attn\", \"attn.c_proj\"]\n",
        "\n",
        "    # OR even simpler - let PEFT find them\n",
        "    target_modules = \"all-linear\"  # This targets all linear layers\n",
        "\n",
        "print(f\"Target modules for LoRA: {target_modules}\")\n",
        "\n",
        "# LoRA configuration\n",
        "peft_config = LoraConfig(\n",
        "    r=LORA_R,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM,\n",
        "    target_modules=target_modules,  # Use the correct modules\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fiujv5Cyhkn",
        "outputId": "67213c4a-b49c-4e6b-8505-5477c07feb2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ LoRA Applied to CodeGen!\n",
            "Trainable parameters: 20,971,520 (0.75%)\n"
          ]
        }
      ],
      "source": [
        "# Apply LoRA\n",
        "model = get_peft_model(model, peft_config)\n",
        "\n",
        "# Enable gradient checkpointing after LoRA\n",
        "model.enable_input_require_grads()\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "# Print trainable parameters\n",
        "trainable_params, total_params = model.get_nb_trainable_parameters()\n",
        "print(f\"\\n LoRA Applied to CodeGen!\")\n",
        "print(f\"Trainable parameters: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sXYIGvQdxiG"
      },
      "source": [
        "# Load and Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574,
          "referenced_widgets": [
            "2989e6a23e0841568dc16ae7c226887e",
            "c41363ddb31347cdb7430b9e053ae9af",
            "191620d08ffc417db376a82e7414f70c",
            "9037808cb16e46b8be98d8bc7d7898ff",
            "f7606ef6199f4089ad6812cf3f06d194",
            "ff0b7f6e040240df82cfc71ee8606fbf",
            "b7abe1db099b404e89ddac62480c78e9",
            "4fbbd87801104f16b5307cc724bcec12",
            "dceca5d3d4fc49c9a2cc6df22b9b9c3e",
            "bfcbe7b42ccc414983a56b94cfa86c2e",
            "a032c6b695514f0180dd503264062dca",
            "226ac1712e3541d582f48b1ef3fe739d",
            "38c3a6520e3c43808d7e71caf2121d70",
            "f8cc55883fd3495f908105d141308e83",
            "c20bbadef6b144e1ac5c73799027795c",
            "355e967435304815bd3bbf578313979f",
            "857a929e2dc0480084c49231af5d0820",
            "df230a10262c46fe97ace907e3e42d4e",
            "541ea233918e4950a34dbeefb6415af5",
            "c6a9e39d6bab4b72b18f45c8f399bf31",
            "6927b009f1444357b5c539bda7d5dbef",
            "567c9cdae3f249c38ae325e8e6578842"
          ]
        },
        "id": "O-WV6xUEwo0R",
        "outputId": "ed1e820e-2969-45a7-e657-9d1702800546"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2989e6a23e0841568dc16ae7c226887e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "226ac1712e3541d582f48b1ef3fe739d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Dataset prepared for CodeGen!\n",
            "   Training samples: 1350\n",
            "   Evaluation samples: 150\n",
            "\n",
            "📝 Sample formatted text:\n",
            "# Question: Create a C# program which takes two strings as parameters, and returns true if the two strings are anagrams of each other.\n",
            "# Input: 'listen', 'silent'\n",
            "# Solution:\n",
            "bool AreAnagrams(string s1, string s2)\n",
            "{\n",
            "    if (s1.Length != s2.Length)\n",
            "        return false;\n",
            " \n",
            "    int[] a = new int[256];\n",
            "    int n = s1.Length;\n",
            "    for (int i = 0; i < n; i++)\n",
            "    {\n",
            "        int c1 = (int)s1[i];\n",
            "        int c2 = (int)s2[i];\n",
            " \n",
            "        a[c1]++;\n",
            "        a[c2]--;\n",
            "    }\n",
            " \n",
            "    for (int i = 0; i < 256; i++)\n",
            "   ...\n"
          ]
        }
      ],
      "source": [
        "# dataset formatting\n",
        "def format_code_dataset_codegen(example):\n",
        "    \"\"\"\n",
        "    Format for CodeGen models - they work best with simple prompts\n",
        "    \"\"\"\n",
        "    # CodeGen prefers this format for Python code\n",
        "    if example.get('input', '').strip():\n",
        "        # With input context\n",
        "        text = f\"\"\"# Question: {example['instruction']}\n",
        "# Input: {example['input']}\n",
        "# Solution:\n",
        "{example['output']}\"\"\"\n",
        "    else:\n",
        "        # Without input - most common case\n",
        "        text = f\"\"\"# {example['instruction']}\n",
        "{example['output']}\"\"\"\n",
        "\n",
        "    return {\"text\": text}\n",
        "\n",
        "# Load and format dataset\n",
        "dataset = load_dataset(DATASET_NAME, split=DATASET_SPLIT)\n",
        "\n",
        "# Apply CodeGen-specific formatting\n",
        "dataset = dataset.map(format_code_dataset_codegen)\n",
        "\n",
        "# Filter for appropriate length\n",
        "def filter_length(example):\n",
        "    # More conservative for CodeGen\n",
        "    return len(example['text']) < SEQ_LENGTH * 3\n",
        "\n",
        "dataset = dataset.filter(filter_length)\n",
        "\n",
        "# Split dataset\n",
        "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "train_dataset = dataset[\"train\"]\n",
        "eval_dataset = dataset[\"test\"]\n",
        "\n",
        "print(f\" Dataset prepared for CodeGen!\")\n",
        "print(f\"   Training samples: {len(train_dataset)}\")\n",
        "print(f\"   Evaluation samples: {len(eval_dataset)}\")\n",
        "print(f\"\\n Sample formatted text:\")\n",
        "print(train_dataset[0][\"text\"][:500] + \"...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr5M5_1Ld0ut"
      },
      "source": [
        "# Configure Training Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSeCpkjRw0F3",
        "outputId": "21be5259-b95a-4896-a640-c62cf3bc9353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Training arguments configured for CodeGen-2B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Optimized training arguments for CodeGen-2B\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./codegen_2b_results\",\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "    gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "    optim=\"paged_adamw_32bit\",  # 32bit works well for 2B model\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=25,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=100,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=200,\n",
        "    save_total_limit=2,\n",
        "    learning_rate=5e-5,  # Lower LR for CodeGen\n",
        "    warmup_steps=100,    # More warmup for stability\n",
        "    fp16=True,           # fp16 for CodeGen\n",
        "    bf16=False,\n",
        "    max_grad_norm=1.0,   # Higher for stability\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    report_to=[],\n",
        "    group_by_length=True,\n",
        "    ddp_find_unused_parameters=False,\n",
        "    dataloader_pin_memory=False,\n",
        ")\n",
        "\n",
        "print(\"Training arguments configured for CodeGen-2B\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFqZVCY-d3OV"
      },
      "source": [
        "# Create Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192,
          "referenced_widgets": [
            "ce1acff55eab4937bd86bbab4cc1eaeb",
            "4073b60267ef45168a9b8479b044b982",
            "e78696238c9f483ab539d99952ee14c8",
            "e6c69f14ddfd473bae6b312db19e348d",
            "cb14fa677764460eab4c0ebd2f16bc5b",
            "3dacb241fc734099b928ce6fb76b7e97",
            "4da358b238ee4abdb23ace5f8e83c2ba",
            "6e8feaed777044d8aac9e8bb4ef856ff",
            "3a0d1c5eacfb4b348141a03b74b8953f",
            "164ff5a0aee94ed18bd76bac2e423c73",
            "02c129c3e344442a8b6b4c9c3e406cd6",
            "4a9493d04bca41f5819cb6f14fc767a7",
            "4675b2d728f94205adf495d86f284ca6",
            "9fafae893d16490aa8dce3a564b00c8a",
            "0e7f4f431826463a98b4b90b005b98cd",
            "4aa0e7ca58c64802a6d85e88e1d1af42",
            "866c3a5e1f434d8b88f6c06c5e0ccebe",
            "387d35927914440fb1070266cd8cf6b7",
            "345ce02fbf9340259830b8013203a416",
            "0b6295e1ee694b3d8ff25e7261e079ce",
            "b14a226a75404719a339c79e16008728",
            "348812cd16434046ae594bda6c00967f"
          ]
        },
        "id": "vWYckIRbw3n5",
        "outputId": "09df9a78-305e-4c6d-828f-dce44c387602"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce1acff55eab4937bd86bbab4cc1eaeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a9493d04bca41f5819cb6f14fc767a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PEFT model created:\n",
            "trainable params: 20,971,520 || all params: 2,800,327,680 || trainable%: 0.7489\n",
            "✅ Trainer created successfully\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:479: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_function(examples):\n",
        "    # Tokenize\n",
        "    result = tokenizer(\n",
        "        examples[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=SEQ_LENGTH\n",
        "    )\n",
        "    # Set labels\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train = train_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "tokenized_eval = eval_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "# Data collator\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False,\n",
        "    pad_to_multiple_of=8\n",
        ")\n",
        "\n",
        "# Apply PEFT configuration to the model\n",
        "model = get_peft_model(model, peft_config)\n",
        "print(\"PEFT model created:\")\n",
        "model.print_trainable_parameters()\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_eval,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "print(\"Trainer created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmyv4us8d6I1"
      },
      "source": [
        "# Training with Monitoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "ARlA4xsxxL5J",
        "outputId": "f4c49e54-2808-4ffd-8974-c44fa83ff861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "============================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='337' max='337' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [337/337 49:09, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.940400</td>\n",
              "      <td>0.828450</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.935800</td>\n",
              "      <td>0.786682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.896800</td>\n",
              "      <td>0.772017</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training completed successfully!\n",
            "\n",
            "--- Training Statistics ---\n",
            "Total time: 49.4 minutes\n",
            "Final loss: 1.0475\n",
            "Samples/second: 0.46\n",
            "Max GPU memory: 6.10 GB\n",
            "---------------------------\n",
            "\n",
            "Success: Model trained well with headroom.\n",
            "Next step: Increase dataset to 500 samples\n",
            "\n",
            "--- GPU Memory After Training ---\n",
            "Allocated: 2.49 GB\n",
            "Reserved: 3.60 GB\n",
            "--------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nStarting training...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Clear cache before training\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    # Train the model\n",
        "    train_result = trainer.train()\n",
        "\n",
        "    # Calculate training statistics\n",
        "    training_time = (time.time() - start_time) / 60\n",
        "    final_loss = train_result.training_loss\n",
        "    samples_per_second = len(train_dataset) / (time.time() - start_time)\n",
        "\n",
        "    print(\"\\nTraining completed successfully!\")\n",
        "    print(f\"\\n--- Training Statistics ---\")\n",
        "    print(f\"Total time: {training_time:.1f} minutes\")\n",
        "    print(f\"Final loss: {final_loss:.4f}\")\n",
        "    print(f\"Samples/second: {samples_per_second:.2f}\")\n",
        "\n",
        "    # Check if we should scale up\n",
        "    max_memory = torch.cuda.max_memory_allocated() / 1024**3\n",
        "    print(f\"Max GPU memory: {max_memory:.2f} GB\")\n",
        "    print(f\"---------------------------\")\n",
        "\n",
        "    if max_memory < 13 and final_loss < 2.0:\n",
        "        print(f\"\\nSuccess: Model trained well with headroom.\")\n",
        "        print(f\"Next step: Increase dataset to 500 samples\")\n",
        "    elif max_memory > 14:\n",
        "        print(f\"\\nWarning: Memory usage high!\")\n",
        "        print(f\"Next step: Keep current settings or reduce LoRA rank\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError: Training failed with error: {e}\")\n",
        "    print(f\"Suggestions:\")\n",
        "    print(f\"- Reduce LoRA rank to 4\")\n",
        "    print(f\"- Reduce Sequence length to 256\")\n",
        "    print(f\"- Reduce Dataset size to 200\")\n",
        "\n",
        "print_gpu_memory(\"After Training\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiacSS84d98i"
      },
      "source": [
        "# Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aCsWVQ0xXpc",
        "outputId": "5cb69f67-b444-4676-8ce8-5de90a9ac571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving model...\n",
            "Model saved to: ./codegen-2B-mono-finetuned\n",
            "Adapter size: 80.0 MB\n"
          ]
        }
      ],
      "source": [
        "# Save the fine-tuned model\n",
        "if 'train_result' in locals():\n",
        "    print(\"\\nSaving model...\")\n",
        "\n",
        "    save_path = f\"./{MODEL_NAME.split('/')[-1]}-finetuned\"\n",
        "    model.save_pretrained(save_path)\n",
        "    tokenizer.save_pretrained(save_path)\n",
        "\n",
        "    print(f\"Model saved to: {save_path}\")\n",
        "\n",
        "    # Calculate adapter size\n",
        "    import os\n",
        "    adapter_size = sum(os.path.getsize(os.path.join(save_path, f))\n",
        "                      for f in os.listdir(save_path)\n",
        "                      if f.endswith('.bin') or f.endswith('.safetensors')) / 1024**2\n",
        "\n",
        "    print(f\"Adapter size: {adapter_size:.1f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BlYlbZ3-WiW",
        "outputId": "f1aade69-61be-4ce3-f045-e9b5f9be823d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model saved for optimization experiments!\n"
          ]
        }
      ],
      "source": [
        "# Add this at the end of your training notebook\n",
        "model.save_pretrained(\"./codegen_finetuned_lora\")\n",
        "tokenizer.save_pretrained(\"./codegen_finetuned_lora\")\n",
        "print(\"Model saved for optimization experiments!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_f3w5zEeQpo"
      },
      "source": [
        "# Test the Fine-tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "777joGoexchh",
        "outputId": "0a14fd1f-6e38-4f5b-bbb9-9509109c3fb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧪 Testing CodeGen-2B for Python code...\n",
            "Prompt: # Write a function to calculate fibonacci numbers\n",
            "\n",
            "------------------------------------------------------------\n",
            "Generated Code:\n",
            "# Write a function to calculate fibonacci numbers\n",
            "def fibonacci(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    else:\n",
            "        return fibonacci(n-1) + fibonacci(n-2)\n",
            "\n",
            "print(fibonacci(10))\n",
            "\n",
            "# Write a function to calculate the sum of the first n natural numbers\n",
            "def sum_natural_numbers(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    else:\n",
            "        return sum_natural_numbers(n-1) + n\n",
            "\n",
            "print(sum_natural_numbers(10))\n",
            "\n",
            "# Write a function to calculate the sum of the first n natural numbers\n",
            "def sum_natural_numbers(n\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n Testing CodeGen-2B for Python code...\")\n",
        "model.config.use_cache = True\n",
        "\n",
        "# CodeGen-specific test prompts\n",
        "test_prompts = [\n",
        "    \"# Write a function to calculate fibonacci numbers\\n\",\n",
        "    \"# Create a function that reverses a string\\n\",\n",
        "    \"# Implement bubble sort in Python\\n\",\n",
        "    \"# Write a class for a stack data structure\\n\",\n",
        "]\n",
        "\n",
        "prompt = test_prompts[0]\n",
        "print(f\"Prompt: {prompt}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Tokenize with CodeGen settings\n",
        "inputs = tokenizer(\n",
        "    prompt,\n",
        "    return_tensors=\"pt\",\n",
        "    return_attention_mask=True\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Generate with CodeGen-optimized parameters\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=150,\n",
        "        temperature=0.2,      # Low for code\n",
        "        do_sample=True,\n",
        "        top_p=0.95,\n",
        "        repetition_penalty=1.0,  # No penalty for code\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Generated Code:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "338654e5",
        "outputId": "1a2459b2-1aac-4815-9af7-4d8e29b986b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Google Drive mounted successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fee68bb",
        "outputId": "45cb054c-f56e-442f-b860-aafe978f7867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copying model from './codegen_finetuned_lora' to './drive/My Drive/my_finetuned_codegen_model'...\n",
            "✅ Model successfully copied to Google Drive!\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Define the source directory  \n",
        "# Make sure this path matches the path used in the saving step  \n",
        "source_dir = \"./codegen_finetuned_lora\" # Or \"./codegen-2B-mono-finetuned\"\n",
        "\n",
        "# Define the destination directory in your Google Drive\n",
        "# Create a new folder name or use an existing one\n",
        "destination_dir = \"./drive/My Drive/my_finetuned_codegen_model\"\n",
        "\n",
        "# Create the destination directory if it doesn't exist\n",
        "os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Copying model from '{source_dir}' to '{destination_dir}'...\")\n",
        "\n",
        "# Copy the contents of the source directory to the destination directory\n",
        "try:\n",
        "    # Use copytree for directories\n",
        "    if os.path.isdir(source_dir):\n",
        "        # Remove destination if it exists to avoid errors with copytree\n",
        "        if os.path.exists(destination_dir):\n",
        "            shutil.rmtree(destination_dir)\n",
        "        shutil.copytree(source_dir, destination_dir)\n",
        "    else:\n",
        "        # Use copy2 for single files if needed (though models are usually directories)\n",
        "        shutil.copy2(source_dir, destination_dir)\n",
        "    print(\" Model successfully copied to Google Drive!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error copying model: {e}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c129c3e344442a8b6b4c9c3e406cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b6295e1ee694b3d8ff25e7261e079ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e7f4f431826463a98b4b90b005b98cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b14a226a75404719a339c79e16008728",
            "placeholder": "​",
            "style": "IPY_MODEL_348812cd16434046ae594bda6c00967f",
            "value": " 150/150 [00:00&lt;00:00, 784.53 examples/s]"
          }
        },
        "164ff5a0aee94ed18bd76bac2e423c73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191620d08ffc417db376a82e7414f70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fbbd87801104f16b5307cc724bcec12",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dceca5d3d4fc49c9a2cc6df22b9b9c3e",
            "value": 1500
          }
        },
        "226ac1712e3541d582f48b1ef3fe739d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38c3a6520e3c43808d7e71caf2121d70",
              "IPY_MODEL_f8cc55883fd3495f908105d141308e83",
              "IPY_MODEL_c20bbadef6b144e1ac5c73799027795c"
            ],
            "layout": "IPY_MODEL_355e967435304815bd3bbf578313979f"
          }
        },
        "2989e6a23e0841568dc16ae7c226887e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c41363ddb31347cdb7430b9e053ae9af",
              "IPY_MODEL_191620d08ffc417db376a82e7414f70c",
              "IPY_MODEL_9037808cb16e46b8be98d8bc7d7898ff"
            ],
            "layout": "IPY_MODEL_f7606ef6199f4089ad6812cf3f06d194"
          }
        },
        "345ce02fbf9340259830b8013203a416": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "348812cd16434046ae594bda6c00967f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "355e967435304815bd3bbf578313979f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "387d35927914440fb1070266cd8cf6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38c3a6520e3c43808d7e71caf2121d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_857a929e2dc0480084c49231af5d0820",
            "placeholder": "​",
            "style": "IPY_MODEL_df230a10262c46fe97ace907e3e42d4e",
            "value": "Filter: 100%"
          }
        },
        "3a0d1c5eacfb4b348141a03b74b8953f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3dacb241fc734099b928ce6fb76b7e97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4073b60267ef45168a9b8479b044b982": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dacb241fc734099b928ce6fb76b7e97",
            "placeholder": "​",
            "style": "IPY_MODEL_4da358b238ee4abdb23ace5f8e83c2ba",
            "value": "Map: 100%"
          }
        },
        "4675b2d728f94205adf495d86f284ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_866c3a5e1f434d8b88f6c06c5e0ccebe",
            "placeholder": "​",
            "style": "IPY_MODEL_387d35927914440fb1070266cd8cf6b7",
            "value": "Map: 100%"
          }
        },
        "4a9493d04bca41f5819cb6f14fc767a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4675b2d728f94205adf495d86f284ca6",
              "IPY_MODEL_9fafae893d16490aa8dce3a564b00c8a",
              "IPY_MODEL_0e7f4f431826463a98b4b90b005b98cd"
            ],
            "layout": "IPY_MODEL_4aa0e7ca58c64802a6d85e88e1d1af42"
          }
        },
        "4aa0e7ca58c64802a6d85e88e1d1af42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da358b238ee4abdb23ace5f8e83c2ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fbbd87801104f16b5307cc724bcec12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "541ea233918e4950a34dbeefb6415af5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567c9cdae3f249c38ae325e8e6578842": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6927b009f1444357b5c539bda7d5dbef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e8feaed777044d8aac9e8bb4ef856ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "857a929e2dc0480084c49231af5d0820": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "866c3a5e1f434d8b88f6c06c5e0ccebe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9037808cb16e46b8be98d8bc7d7898ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfcbe7b42ccc414983a56b94cfa86c2e",
            "placeholder": "​",
            "style": "IPY_MODEL_a032c6b695514f0180dd503264062dca",
            "value": " 1500/1500 [00:00&lt;00:00, 3858.02 examples/s]"
          }
        },
        "9fafae893d16490aa8dce3a564b00c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_345ce02fbf9340259830b8013203a416",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b6295e1ee694b3d8ff25e7261e079ce",
            "value": 150
          }
        },
        "a032c6b695514f0180dd503264062dca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b14a226a75404719a339c79e16008728": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7abe1db099b404e89ddac62480c78e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfcbe7b42ccc414983a56b94cfa86c2e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c20bbadef6b144e1ac5c73799027795c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6927b009f1444357b5c539bda7d5dbef",
            "placeholder": "​",
            "style": "IPY_MODEL_567c9cdae3f249c38ae325e8e6578842",
            "value": " 1500/1500 [00:00&lt;00:00, 23588.07 examples/s]"
          }
        },
        "c41363ddb31347cdb7430b9e053ae9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff0b7f6e040240df82cfc71ee8606fbf",
            "placeholder": "​",
            "style": "IPY_MODEL_b7abe1db099b404e89ddac62480c78e9",
            "value": "Map: 100%"
          }
        },
        "c6a9e39d6bab4b72b18f45c8f399bf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb14fa677764460eab4c0ebd2f16bc5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1acff55eab4937bd86bbab4cc1eaeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4073b60267ef45168a9b8479b044b982",
              "IPY_MODEL_e78696238c9f483ab539d99952ee14c8",
              "IPY_MODEL_e6c69f14ddfd473bae6b312db19e348d"
            ],
            "layout": "IPY_MODEL_cb14fa677764460eab4c0ebd2f16bc5b"
          }
        },
        "dceca5d3d4fc49c9a2cc6df22b9b9c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df230a10262c46fe97ace907e3e42d4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6c69f14ddfd473bae6b312db19e348d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_164ff5a0aee94ed18bd76bac2e423c73",
            "placeholder": "​",
            "style": "IPY_MODEL_02c129c3e344442a8b6b4c9c3e406cd6",
            "value": " 1350/1350 [00:01&lt;00:00, 764.49 examples/s]"
          }
        },
        "e78696238c9f483ab539d99952ee14c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e8feaed777044d8aac9e8bb4ef856ff",
            "max": 1350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a0d1c5eacfb4b348141a03b74b8953f",
            "value": 1350
          }
        },
        "f7606ef6199f4089ad6812cf3f06d194": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cc55883fd3495f908105d141308e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_541ea233918e4950a34dbeefb6415af5",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6a9e39d6bab4b72b18f45c8f399bf31",
            "value": 1500
          }
        },
        "ff0b7f6e040240df82cfc71ee8606fbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
